{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hacker_news](hacker_news.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploring Hacker News Posts\n",
    "\n",
    "In this project, we'll work with a data set of submissions to popular technology site Hacker News.\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "You can find the data set here, but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "*id: The unique identifier from Hacker News for the post\n",
    "    \n",
    "*title: The title of the post\n",
    "    \n",
    "*url: The URL that the posts links to, if it the post has a URL\n",
    "\n",
    "*num_points: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "    \n",
    "*num_comments: The number of comments that were made on the post\n",
    "    \n",
    "*author: The username of the person who submitted the post\n",
    "    \n",
    "*created_at: The date and time at which the post was submitted\n",
    "     \n",
    "Here is the example of one of the rows in the data set:\n",
    "\n",
    "*id: 12224879\t\n",
    "*title: Interactive Dynamic Video\t\n",
    "*url: http://www.interactivedynamicvideo.com/\n",
    "*num_points: 386\t\n",
    "*num_comments: 52\t\n",
    "*author: ne0phyte\t\n",
    "*created_at: 8/4/2016 11:52\n",
    "\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either Ask HN or Show HN. Users submit Ask HN posts to ask the Hacker News community a specific question. Below are a couple examples:\n",
    "\n",
    "\n",
    "\n",
    "*Ask HN: How to improve my personal website?\n",
    "\n",
    "*Ask HN: Am I the only one outraged by Twitter shutting down share counts?\n",
    "\n",
    "*Ask HN: Aby recent changes to CSS that broke mobile?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Likewise, users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting. Below are a couple of examples:\n",
    "\n",
    "\n",
    "\n",
    "*Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform'\n",
    "\n",
    "*Show HN: Something pointless I made\n",
    "\n",
    "*Show HN: Shanhu.io, a programming playground powered by e8vm\n",
    "\n",
    "\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "\n",
    "*Do Ask HN or Show HN receive more comments on average?\n",
    "\n",
    "*Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "\n",
    "## Data Exploration & Preparation\n",
    "\n",
    "Let's start by importing the libraries we need and reading the data set into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from csv import reader\n",
    "\n",
    "open_file = open('hacker_news.csv')\n",
    "read_file = reader(open_file)\n",
    "hn = list(read_file)\n",
    "headers = hn[0]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only concerned about post titles beginning with Ask HN or Show HN, we will extract the rows containing just the data for those titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = (row[1].lower())\n",
    "    if (title.startswith('ask hn')):\n",
    "        ask_posts.append(row)\n",
    "    elif (title.startswith('show hn')):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average amount of ask comments per post:  14.038417431192661\n",
      "Average amount of show comments per post:  10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(\"Average amount of ask comments per post: \",avg_ask_comments)\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(\"Average amount of show comments per post: \",avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the average amount of comments for ask posts is ~14 and precedes the amount of show posts i.e. ~10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, on average, ask posts receive more comments than show posts. Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "1.Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "\n",
    "2.Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by hour:\n",
      "18 109\n",
      "14 107\n",
      "22 71\n",
      "02 58\n",
      "21 109\n",
      "09 45\n",
      "05 46\n",
      "03 54\n",
      "06 44\n",
      "10 59\n",
      "00 55\n",
      "19 110\n",
      "08 48\n",
      "13 85\n",
      "15 116\n",
      "23 68\n",
      "20 80\n",
      "07 34\n",
      "11 58\n",
      "17 100\n",
      "04 47\n",
      "16 108\n",
      "12 73\n",
      "01 60\n",
      "\n",
      "Comments by hour:\n",
      "18 1439\n",
      "14 1416\n",
      "22 479\n",
      "02 1381\n",
      "21 1745\n",
      "09 251\n",
      "05 464\n",
      "03 421\n",
      "06 397\n",
      "10 793\n",
      "00 447\n",
      "19 1188\n",
      "08 492\n",
      "13 1253\n",
      "15 4477\n",
      "23 543\n",
      "20 1722\n",
      "07 267\n",
      "11 641\n",
      "17 1146\n",
      "04 337\n",
      "16 1814\n",
      "12 687\n",
      "01 683\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# looping over the ask posts and\n",
    "# appending the create-date and number of comments as a list to the result_list \n",
    "for item in ask_posts:\n",
    "    created_at = item[6]\n",
    "    comments = int(item[4])\n",
    "    result_list.append([created_at, comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "# Looping throught the result_list\n",
    "# extracting the created_at-time from the date\n",
    "# creating a datetime-object for this time\n",
    "# Select just the hour from our date-time object\n",
    "for item in result_list:\n",
    "    created_at = item[0]\n",
    "    comments = item[1]\n",
    "    dt_hour = dt.datetime.strptime(created_at, \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt_hour.strftime(\"%H\")\n",
    "    # check if the hour is in the dictionaries\n",
    "    # if not, create an entry in both.  If it is, add an entry in both\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "\n",
    "# let's see how that went\n",
    "print (\"Counts by hour:\")\n",
    "for key, value in counts_by_hour.items():\n",
    "    print(key, value)\n",
    "print() # blank line to separate\n",
    "print (\"Comments by hour:\")\n",
    "for key, value in comments_by_hour.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have the number of Ask posts created each hour of the day, and the number of comments each received, we can proceed with step 2:\n",
    "\n",
    "*calculate the average number of comments Ask posts received each hour of the day.\n",
    "\n",
    "For example, on the hour of 15 PM there were 116 Ask posts that received 4477 comments, so on average 4477/116 = 38,59 comments per post. To calculate this for each hour we will iterate over the two dictionaries we created in the previous step: For each hour in comments by hour we will get the hour-key and the corresponding comments-value, and divide this value by the corresponding posts-value for the same hour-key in counts_by_hour. Every iteration is appended to a new list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['18', 13.20183486238532]\n",
      "['14', 13.233644859813085]\n",
      "['22', 6.746478873239437]\n",
      "['02', 23.810344827586206]\n",
      "['21', 16.009174311926607]\n",
      "['09', 5.5777777777777775]\n",
      "['05', 10.08695652173913]\n",
      "['03', 7.796296296296297]\n",
      "['06', 9.022727272727273]\n",
      "['10', 13.440677966101696]\n",
      "['00', 8.127272727272727]\n",
      "['19', 10.8]\n",
      "['08', 10.25]\n",
      "['13', 14.741176470588234]\n",
      "['15', 38.5948275862069]\n",
      "['23', 7.985294117647059]\n",
      "['20', 21.525]\n",
      "['07', 7.852941176470588]\n",
      "['11', 11.051724137931034]\n",
      "['17', 11.46]\n",
      "['04', 7.170212765957447]\n",
      "['16', 16.796296296296298]\n",
      "['12', 9.41095890410959]\n",
      "['01', 11.383333333333333]\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour,comments_by_hour[hour]/(counts_by_hour[hour])])\n",
    "\n",
    "for element in avg_by_hour:\n",
    "    print(element, sep = '\\n') \n",
    "print(type(avg_by_hour[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 hours for Ask Posts Comments:\n",
      "\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "\n",
    "sorted_swap = (sorted(swap_avg_by_hour, reverse = True))\n",
    "print()    \n",
    "print(\"Top 5 hours for Ask Posts Comments:\")\n",
    "print()\n",
    "for element in sorted_swap[0:5]:\n",
    "    avg_comments = (\"{:.2f}\".format(element[0]))\n",
    "    hour = element[1]\n",
    "    hour_obj = dt.datetime.strptime(hour,\"%H\")\n",
    "    hour_str = hour_obj.strftime(\"%H:%M\")\n",
    "    print(\"{0}: {1} average comments per post\".format(hour_str, avg_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "So to conclude there seem to be three time slots for creating Ask posts that have a high chance of receiving comments:\n",
    "\n",
    "Between 15-17h in the afternoon Eastern Time U.S. (21-23h CET)\n",
    "Between 20-22h in the evening Eastern Time U.S. (02-04h CET)\n",
    "Between 02-03h at night Eastern Time U.S. (8-9h CET)\n",
    "That should give you plenty of options for choosing the right moment for creating your Ask post and sit back to enjoy seeing the comments roll in.\n",
    "\n",
    "That's all on this analysis for now!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
